import { InferenceClient } from "@huggingface/inference";

const HF_TOKEN = import.meta.env.VITE_HF_ACCESS_TOKEN;

const SYSTEM_PROMPT = `
You are an assistant that receives a list of ingredients that a user has and suggests a recipe they could make with some or all of those ingredients. You don't need to use every ingredient they mention in your recipe. The recipe can include additional ingredients they didn't mention, but try not to include too many extra ingredients. Start with the recipe name with ##. Format your response in markdown to make it easier to render to a web page
`;

const hf = new InferenceClient(HF_TOKEN);

export default async function getRecipeFromMistral(ingredientsArr) {
    if (!hf) {
        return "Error: Hugging Face client failed to initialize due to a missing token. Check the console for instructions.";
    }

    const ingredientsString = ingredientsArr.join(", ");
    const userMessage = `I have ${ingredientsString}. Please give me a recipe you'd recommend I make!`;

    try {
        const response = await hf.chatCompletion({
            model: "meta-llama/Llama-3.2-1B-Instruct",
            messages: [
                { role: "system", content: SYSTEM_PROMPT.trim() },
                {
                    role: "user",
                    content: userMessage,
                },
            ],
            max_tokens: 1024,
        });

        return response.choices[0].message.content;
    } catch (err) {
        console.error(err.message);
    }
}
